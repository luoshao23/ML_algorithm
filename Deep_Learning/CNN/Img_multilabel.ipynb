{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from SR_module import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luo.sz/beLLE/data/mst\n"
     ]
    }
   ],
   "source": [
    "ROOT = os.environ.get('DATA', os.path.join(\n",
    "    os.path.dirname(os.path.abspath('..')), 'data', 'mst'))\n",
    "print(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(img_list): \n",
    "\n",
    "    imgs = []\n",
    "    for img_path in img_list:\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        imgs.append(x)\n",
    "\n",
    "    imgs = np.concatenate(imgs, 0)\n",
    "    imgs = preprocess_input(imgs)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"春\"\n",
    "\n",
    "prop_name = '%dspring_m.csv' if season == \"春\" else '%dsummer_m.csv'\n",
    "PROP_COLS = [ u'产品系列(旧)',  u'帮面材质-主要', u'款型', u'跟型', u'楦型',\n",
    "                  u'跟高',  u'帮面颜色', u'鞋头', u'开口深浅', u'有无配饰', u'穿法', u'帮面材质唯一']\n",
    "COLS = [u'产品系列(旧)', u'款型',u'跟型',u'跟高',u'帮面颜色',u'有无配饰']\n",
    "feature_num = len(COLS)\n",
    "PROP = []\n",
    "for yr in range(2016, 2019):\n",
    "    prop = data_prop(os.path.join(ROOT, prop_name%(yr%100)))\n",
    "    PROP.append(prop) \n",
    "\n",
    "p_total = pd.concat(PROP)[COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_list(img_root, prop_index):\n",
    "    ext = 'jpg'\n",
    "    base_list = os.listdir(img_root)\n",
    "    img_code = [f.split('.')[0] for f in base_list if f.endswith(ext)]\n",
    "    final_code = p_total.index.intersection(img_code).tolist()\n",
    "    return final_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_X_y(img_root, prop_index, multiout=False):\n",
    "    \n",
    "    f_code = common_list(img_root, prop_index)\n",
    "\n",
    "    file_list = [os.path.join(img_root, '%s.jpg'%f) for f in f_code]\n",
    "    imgs = load_img(file_list)\n",
    "    labels = p_total.loc[f_code]\n",
    "    \n",
    "    if multiout:\n",
    "        label_one = []\n",
    "        for col in labels.columns:\n",
    "            label_one.append(pd.get_dummies(labels[col]).values)\n",
    "    else:\n",
    "        label_one = pd.get_dummies(labels).values\n",
    "    \n",
    "    return imgs, label_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi output\n",
    "img_roots = ['/home/luo.sz/beLLE/data/imgs/', '/home/luo.sz/beLLE/data/ygimgs/']\n",
    "X_li = []\n",
    "y_li = []\n",
    "for root in img_roots:\n",
    "    imgs, label_one = gen_X_y(root, p_total.index, multiout=True)\n",
    "    X_li.append(imgs)\n",
    "    y_li.append(label_one)\n",
    "\n",
    "\n",
    "X = np.concatenate(X_li, axis=0)\n",
    "y = [np.concatenate([y_[i] for y_ in y_li], axis=0) for i in range(feature_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X, y = np.concatenate([img16, img17], axis=0), np.concatenate([label_one16.toarray(), label_one17.toarray()], axis=0)\n",
    "\n",
    "total_len = X.shape[0]\n",
    "train_len = int(total_len * 0.9)\n",
    "\n",
    "\n",
    "np.random.seed(23)\n",
    "random_index = np.random.permutation(total_len)\n",
    "train_index, test_index = random_index[:train_len], random_index[train_len:]\n",
    "X_train, y_train = X[train_index, :], [y_[train_index, :] for y_ in y]\n",
    "X_test, y_test = X[test_index, :], [y_[test_index, :] for y_ in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BelleNet(input_shape=(224, 224, 3), labels=29):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(labels, activation='sigmoid'))  ## !IMPORTANT: use sigmoid in multi-label task\n",
    "    \n",
    "    return model\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "def BelleMultiNet(input_shape=(224, 224, 3), labels=[3,6,7,4,4,2]):\n",
    "    label_len = len(labels)\n",
    "    input_ = Input(shape=input_shape, name='input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu', name='extract')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    mid = [Dense(128, activation='relu')(x) for _ in range(label_len)]\n",
    "    mid = [Dense(64, activation='relu')(m) for m in mid]\n",
    "    mid = [Dense(64, activation='relu')(m) for m in mid]\n",
    "    \n",
    "    outs = []\n",
    "    for i, m, l in zip(range(label_len), mid, labels):\n",
    "        outs.append(Dense(l, activation='softmax', name='out'+str(i+1))(m))\n",
    "    \n",
    "    model = Model(inputs=input_, outputs=outs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 70 #70 is enough\n",
    "\n",
    "model = BelleMultiNet(labels=[y_.shape[1] for y_ in y])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics={'out%d'%(i+1):'categorical_accuracy' for i in range(feature_num)})\n",
    "# model.fit(X_train, y_train, batch_size=32, epochs=10)\n",
    "\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = image.ImageDataGenerator( rescale=1./255)\n",
    "\n",
    "model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=32, multiout=True),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.750553393363953,\n",
       " 0.3793038740754128,\n",
       " 0.9147469818592071,\n",
       " 0.5966550067067147,\n",
       " 0.512187322974205,\n",
       " 1.6708511054515838,\n",
       " 0.676808986067772,\n",
       " 0.890625,\n",
       " 0.81875,\n",
       " 0.84375,\n",
       " 0.875,\n",
       " 0.675,\n",
       " 0.79375]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_datagen.flow(X_test, y_test, multiout=True), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **V1** is trained using **one** img repo, while\n",
    "+ **V2** is trained using **two** img repos, `/home/luo.sz/beLLE/data/imgs/` and `/home/luo.sz/beLLE/data/ygimgs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(ROOT, 'BelleMultiNet_Weights_V2.h5')) \n",
    "json_string = model.to_json()\n",
    "with open(os.path.join(ROOT, 'BelleMultiNet_V2.json'), 'w') as f:\n",
    "    f.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 100 #70 is enough\n",
    "\n",
    "model = BelleNet(labels=y_test.shape[1])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']) ## !IMPORTANT: use binary_crossentropy in multi-label task\n",
    "\n",
    "\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = image.ImageDataGenerator( rescale=1./255)\n",
    "\n",
    "model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=epochs)\n",
    "\n",
    "# model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(test_datagen.flow(X_test, y_test), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(ROOT, 'BelleNet_Weights.h5')) \n",
    "json_string = model.to_json()\n",
    "with open(os.path.join(ROOT, 'BelleNet.json'), 'w') as f:\n",
    "    f.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
