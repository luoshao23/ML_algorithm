{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': '/tmp/mnist_convnet_model', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-201\n",
      "INFO:tensorflow:Saving checkpoints for 202 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2577, step = 202\n",
      "INFO:tensorflow:global_step/sec: 5.14336\n",
      "INFO:tensorflow:loss = 2.24191, step = 302 (19.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.76332\n",
      "INFO:tensorflow:loss = 2.22952, step = 402 (20.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.17879\n",
      "INFO:tensorflow:loss = 2.17337, step = 502 (23.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44531\n",
      "INFO:tensorflow:loss = 2.14476, step = 602 (22.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.24176\n",
      "INFO:tensorflow:loss = 2.12841, step = 702 (19.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.12082\n",
      "INFO:tensorflow:loss = 1.99575, step = 802 (19.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.85169\n",
      "INFO:tensorflow:loss = 1.96625, step = 902 (20.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.31015\n",
      "INFO:tensorflow:loss = 1.91727, step = 1002 (18.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.17021\n",
      "INFO:tensorflow:loss = 1.74486, step = 1102 (19.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.26404\n",
      "INFO:tensorflow:loss = 1.57992, step = 1202 (30.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.90514\n",
      "INFO:tensorflow:loss = 1.4793, step = 1302 (20.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.8124\n",
      "INFO:tensorflow:loss = 1.24084, step = 1402 (20.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.12563\n",
      "INFO:tensorflow:loss = 0.944429, step = 1502 (19.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.4055\n",
      "INFO:tensorflow:loss = 0.880275, step = 1602 (18.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.37937\n",
      "INFO:tensorflow:loss = 0.741957, step = 1702 (18.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.27733\n",
      "INFO:tensorflow:loss = 0.802933, step = 1802 (18.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.74714\n",
      "INFO:tensorflow:loss = 0.549236, step = 1902 (21.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.79841\n",
      "INFO:tensorflow:loss = 0.818456, step = 2002 (20.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.90897\n",
      "INFO:tensorflow:loss = 0.770689, step = 2102 (20.376 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2201 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.617396.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-18-13:05:30\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-2201\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-18-13:05:36\n",
      "INFO:tensorflow:Saving dict for global step 2201: accuracy = 0.8668, global_step = 2201, loss = 0.537884\n",
      "{'loss': 0.53788447, 'global_step': 2201, 'accuracy': 0.86680001}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, \n",
    "                             kernel_size=[5, 5], padding='same',\n",
    "                            activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[5, 5], \n",
    "                             padding='same', activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7*7*64])\n",
    "    \n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    \n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        'classes': tf.argmax(input=logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "def main(unused_argv):\n",
    "    # Load training and eval data\n",
    "    mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "    train_data = mnist.train.images  # Returns np.array\n",
    "    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "    eval_data = mnist.test.images  # Returns np.array\n",
    "    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "    # Create the Estimator\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "    mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=2000)\n",
    "\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.losses.softmax_cross_entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
